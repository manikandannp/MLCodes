{"cells": [{"metadata": {}, "cell_type": "markdown", "source": "T-test using Python and Numpy:\nhttps://towardsdatascience.com/inferential-statistics-series-t-test-using-numpy-2718f8f9bf2f\n\nHow to Code the Student\u2019s t-Test from Scratch in Python:\nhttps://machinelearningmastery.com/how-to-code-the-students-t-test-from-scratch-in-python/\n    \nStatistical Comparison of Two Groups:\nhttps://www.texasoft.com/tutorial-statistics-compare-2-groups.htm\n    \nIndependent t-test example in R:\nhttps://www.kaggle.com/kappernielsen/independent-t-test-example"}, {"metadata": {}, "cell_type": "code", "source": "import pandas as pd\nimport numpy as np\nfrom scipy import stats\ndataset = pd.read_csv('C:/Users/ShatheepR/Desktop/data.csv')", "execution_count": 83, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "dataset = dataset.fillna(0)\ndataset.head(3)", "execution_count": 84, "outputs": [{"output_type": "execute_result", "execution_count": 84, "data": {"text/plain": "      URN_IDM_COMP ATTENDED?  20191H-20202H  2019_Qtr1  2019_Qtr2  2019_Qtr3  \\\n0  100951108049095       YES       2.154446   2.180879  22.314170   0.006000   \n1  106701107167088       YES      11.157098   6.705002  66.108255   4.009514   \n2  107271106276398        NO     140.826056   3.399301  90.712748  16.654267   \n\n   2019_Qtr4  2020_Qtr1  2020_Qtr2  2020_Qtr3  2020_Qtr4  \n0   2.148446   0.000000   0.000000   0.131084   0.456592  \n1   2.135232   2.359942   2.652410   3.381500  44.377540  \n2  23.963908  19.355122  80.852759  20.779204  25.300066  ", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>URN_IDM_COMP</th>\n      <th>ATTENDED?</th>\n      <th>20191H-20202H</th>\n      <th>2019_Qtr1</th>\n      <th>2019_Qtr2</th>\n      <th>2019_Qtr3</th>\n      <th>2019_Qtr4</th>\n      <th>2020_Qtr1</th>\n      <th>2020_Qtr2</th>\n      <th>2020_Qtr3</th>\n      <th>2020_Qtr4</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>100951108049095</td>\n      <td>YES</td>\n      <td>2.154446</td>\n      <td>2.180879</td>\n      <td>22.314170</td>\n      <td>0.006000</td>\n      <td>2.148446</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.131084</td>\n      <td>0.456592</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>106701107167088</td>\n      <td>YES</td>\n      <td>11.157098</td>\n      <td>6.705002</td>\n      <td>66.108255</td>\n      <td>4.009514</td>\n      <td>2.135232</td>\n      <td>2.359942</td>\n      <td>2.652410</td>\n      <td>3.381500</td>\n      <td>44.377540</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>107271106276398</td>\n      <td>NO</td>\n      <td>140.826056</td>\n      <td>3.399301</td>\n      <td>90.712748</td>\n      <td>16.654267</td>\n      <td>23.963908</td>\n      <td>19.355122</td>\n      <td>80.852759</td>\n      <td>20.779204</td>\n      <td>25.300066</td>\n    </tr>\n  </tbody>\n</table>\n</div>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "dataset['20191H-20202H'] = dataset['2019_Qtr3'] + dataset['2019_Qtr4']", "execution_count": 85, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "dataset.rename(columns = {'20191H-20202H': 'target'}, inplace = True)", "execution_count": 86, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "dataset = dataset.filter([\"ATTENDED?\", \"target\"]) #, \"URN_IDM_COMP\"\ndataset.head(3)", "execution_count": 87, "outputs": [{"output_type": "execute_result", "execution_count": 87, "data": {"text/plain": "  ATTENDED?     target\n0       YES   2.154446\n1       YES   6.144746\n2        NO  40.618175", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ATTENDED?</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>YES</td>\n      <td>2.154446</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>YES</td>\n      <td>6.144746</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>NO</td>\n      <td>40.618175</td>\n    </tr>\n  </tbody>\n</table>\n</div>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "dataset['target'].sum()", "execution_count": 88, "outputs": [{"output_type": "execute_result", "execution_count": 88, "data": {"text/plain": "9577.831995999999"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "## Define 2 distributions\na = dataset[(dataset[\"ATTENDED?\"] == 'YES') & (dataset[\"target\"] >0)][\"target\"]\nb = dataset[(dataset[\"ATTENDED?\"] == 'NO') & (dataset[\"target\"] >0)][\"target\"]\ndataset = dataset[dataset[\"target\"] >0][\"target\"]", "execution_count": 89, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Check whether the distribution is Gaussian or not through Shapiro-Wilk Test\nfrom scipy.stats import shapiro\n#stat, p = shapiro(dataset)\n\n# Example of the D'Agostino's K^2 Normality Test\nfrom scipy.stats import normaltest\nstat, p = normaltest(dataset)\n\nprint('stat={0:.3f}, p={0:.3f}' .format(stat, p))\nif p > 0.05:\n    print('Probably Gaussian')\nelse:\n    print('Probably not Gaussian')", "execution_count": 90, "outputs": [{"output_type": "stream", "text": "stat=748.948, p=748.948\nProbably not Gaussian\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "# Example of the Anderson-Darling Normality Test\nfrom scipy.stats import anderson\nresult = anderson(dataset)\nprint('stat={0:.3g}'.format(result.statistic))\nfor i in range(len(result.critical_values)):\n    sl, cv = result.significance_level[i], result.critical_values[i]\n    if result.statistic < cv:\n        print('Probably Gaussian at the %.1f%% level' % (sl))\n    else:\n        print('Probably not Gaussian at the %.1f%% level' % (sl))", "execution_count": 91, "outputs": [{"output_type": "stream", "text": "stat=142\nProbably not Gaussian at the 15.0% level\nProbably not Gaussian at the 10.0% level\nProbably not Gaussian at the 5.0% level\nProbably not Gaussian at the 2.5% level\nProbably not Gaussian at the 1.0% level\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "# Example of the Analysis of Variance Test - ANOVA\nfrom scipy.stats import f_oneway\nstat, p = f_oneway(a, b)\nprint('stat={0:.3g}, p={0:.3g}'.format(stat, p))\nif p > 0.05:\n    print('Probably the same distribution')\nelse:\n    print('Probably different distributions')", "execution_count": 92, "outputs": [{"output_type": "stream", "text": "stat=3.59, p=3.59\nProbably the same distribution\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "Nonparametric Statistical Hypothesis Tests\nhttps://www.kaggle.com/shashwatwork/guide-to-statistical-hypothesis-tests-in-python"}, {"metadata": {}, "cell_type": "code", "source": "# Example of the Mann-Whitney U Test\n#Distribution of two data samples are equal or not.\nfrom scipy.stats import mannwhitneyu\nstat, p = mannwhitneyu(a, b)\nprint('stat={0:.3g}, p={0:.3g}'.format(stat, p))\nif p > 0.05:\n    print('Probably the same distribution')\nelse:\n    print('Probably different distributions')", "execution_count": 93, "outputs": [{"output_type": "stream", "text": "stat=1.86e+04, p=1.86e+04\nProbably different distributions\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "## Calculate the Standard Deviation\n#Calculate the variance to get the standard deviation\n#For unbiased max likelihood estimate we have to divide the var by N-1, and therefore the parameter ddof = 1\nvar_a = a.var(ddof=1)\nvar_b = b.var(ddof=1)\nprint(\"Variance of a: \" + str(var_a))\nprint(\"Variance of b: \" + str(var_b))", "execution_count": 94, "outputs": [{"output_type": "stream", "text": "Variance of a: 3785.5725137647855\nVariance of b: 3816.833601336582\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "#std deviation\ntd = np.sqrt((var_a/ a.shape[0]) + (var_b/ b.shape[0])) # Gives number of rows\ntd", "execution_count": 95, "outputs": [{"output_type": "execute_result", "execution_count": 95, "data": {"text/plain": "6.124854497519931"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "## Calculate the t-statistics\nt = (a.mean() - b.mean())/td", "execution_count": 96, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "## Compare with the critical t-value\n#Degrees of freedom\n#N = dataset.shape[0]\ndf = a.shape[0] + b.shape[0] - 2\ndf", "execution_count": 97, "outputs": [{"output_type": "execute_result", "execution_count": 97, "data": {"text/plain": "562"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "# calculate the critical t value\nalpha = 0.05\ncv = stats.t.ppf(1.0 - alpha, df)\ncv", "execution_count": 98, "outputs": [{"output_type": "execute_result", "execution_count": 98, "data": {"text/plain": "1.6475694620295673"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "#p-value after comparison with the t \np = 1 - stats.t.cdf(abs(t),df=df)\n\nprint(\"t = \" + str(t))\nprint(\"p = \" + str(2*p))\n### You can see that after comparing the t statistic with the critical t value (computed internally) we get a good p value of 0.0005 and thus we reject the null hypothesis and thus it proves that the mean of the two distributions are different and statistically significant.\n## Cross Checking with the internal scipy function\n# Use scipy.stats.ttest_ind.\nt2, p2 = stats.ttest_ind(a,b, equal_var=False) #, equal_var=False\nprint(\"ttest_ind:            t2 = %g  p2 = %g\" % (t2, p2))", "execution_count": 99, "outputs": [{"output_type": "stream", "text": "t = 1.8984330749459415\np = 0.058151053012823306\nttest_ind:            t2 = 1.89843  p2 = 0.0589607\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# interpret via critical value\nif abs(t) <= cv:\n    print('Accept null hypothesis that the means are equal.')\nelse:\n    print('Reject the null hypothesis that the means are equal.')", "execution_count": 100, "outputs": [{"output_type": "stream", "text": "Reject the null hypothesis that the means are equal.\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "# interpret via p-value\nif p > alpha:\n    print('Accept null hypothesis that the means are equal.')\nelse:\n    print('Reject the null hypothesis that the means are equal.')", "execution_count": 101, "outputs": [{"output_type": "stream", "text": "Reject the null hypothesis that the means are equal.\n", "name": "stdout"}]}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3", "language": "python"}, "language_info": {"name": "python", "version": "3.6.8", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 1}